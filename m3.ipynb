{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poezdki1 = df_poezdki.groupby(by=['station','line','hour'])[['num_val','date']].agg({'num_val' : 'sum', 'date' : 'max'})\n",
    "df_poezdki1=df_poezdki1.reset_index()\n",
    "df_poezdki1['download_station'] = df_poezdki1.groupby(by=['station','hour'])['num_val'].transform('max')\n",
    "df_poezdki1['mean_bandwidth'] = df_poezdki1.groupby(by=['station','hour'])['num_val'].transform('mean')\n",
    "df_poezdki1['bandwidth'] = df_poezdki1['download_station']*100/df_poezdki1['mean_bandwidth']\n",
    "\n",
    "df_poezdki1\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3, random_state=42, n_init=300)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le1 = LabelEncoder()\n",
    "df_poezdki1['station']=le1.fit_transform(df_poezdki1['station'])\n",
    "le2 = LabelEncoder()\n",
    "df_poezdki1['line']=le2.fit_transform(df_poezdki1['line'])\n",
    "le2 = LabelEncoder()\n",
    "df_poezdki1['date']=le2.fit_transform(df_poezdki1['date'])\n",
    "cluster= model.fit_predict(df_poezdki1)\n",
    "df_poezdki1['cluster'] = cluster\n",
    "\n",
    "df = df_poezdki1.copy()\n",
    "df['labels'] = model.labels_\n",
    "df['labels'] = df.labels.astype('category')\n",
    "pd.set_option('display.max_rows', 80) # для удосбтва анализа делаем\n",
    "df.groupby('labels', observed=True).agg(['count','mean', 'std']).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка набора данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделяем на X и y\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разделение данных на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=200)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решающее дерево\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=100)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "y_pred_forest = forest_clf.predict(X_test)\n",
    "accuracy_forest = accuracy_score(y_test, y_pred_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 1.0\n",
      "Accuracy of Decision Tree: 1.0\n",
      "Accuracy of Random Forest: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Logistic Regression:\", accuracy_log_reg)\n",
    "print(\"Accuracy of Decision Tree:\", accuracy_tree)\n",
    "print(\"Accuracy of Random Forest:\", accuracy_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Организация непрерывного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "\n",
    "# Функция для загрузки новых данных из базы данных\n",
    "def load_new_data():\n",
    "    conn = sqlite3.connect('transport.db')\n",
    "    query = \"SELECT * FROM trips WHERE timestamp > (SELECT MAX(timestamp) FROM model_training_log)\"\n",
    "    new_data = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return new_data\n",
    "\n",
    "# Функция для дообучения модели\n",
    "def retrain_model():\n",
    "    # Загружаем новые данные\n",
    "    new_data = load_new_data()\n",
    "    \n",
    "    if new_data.empty:\n",
    "        print(\"No new data available for training.\")\n",
    "        return\n",
    "    \n",
    "    # Предобработка данных\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    kmeans = joblib.load('kmeans_model.pkl')\n",
    "    new_data_scaled = scaler.transform(new_data[['val_num', 'hour', 'metriki', 'input_stair', 'output_stair', 'count_stair',\n",
    "                                                  'input_door', 'output_door', 'count_door', 'input_escalator', 'output_escalator', 'count_escalator']])\n",
    "    \n",
    "    # Дообучение модели\n",
    "    kmeans.partial_fit(new_data_scaled)\n",
    "    \n",
    "    # Сохраняем обновленную модель\n",
    "    joblib.dump(kmeans, 'kmeans_model.pkl')\n",
    "    \n",
    "    # Обновляем лог дообучения\n",
    "    conn = sqlite3.connect('transport.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"INSERT INTO model_training_log (timestamp) VALUES (datetime('now'))\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Создаем DAG\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2023, 1, 1),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5)\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'retrain_model_dag',\n",
    "    default_args=default_args,\n",
    "    description='Retrain model every 5 minutes',\n",
    "    schedule_interval=timedelta(minutes=5),\n",
    ")\n",
    "\n",
    "# Операторы для выполнения задач\n",
    "retrain_task = PythonOperator(\n",
    "    task_id='retrain_model',\n",
    "    python_callable=retrain_model,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "retrain_task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Прогнозирование динамики изменения характеристик\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_poezdki.copy()\n",
    "df=df.sort_values(by='date')\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Убедитесь, что данные упорядочены по дате\n",
    "df = df.asfreq('D').fillna(0)  # Заполнение пропущенных значений нулями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Игнорирование предупреждений, связанных с ARIMA\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Проверка стационарности временного ряда с помощью теста Дики-Фуллера\n",
    "result = adfuller(df['num_val'])\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "\n",
    "# Дифференцирование для получения стационарного временного ряда\n",
    "df['total_load_diff'] = df['num_val'].diff().dropna()\n",
    "\n",
    "# Подбор параметров ARIMA (p, d, q) с использованием функции auto_arima\n",
    "# from pmdarima import auto_arima\n",
    "# auto_model = auto_arima(df['total_load'], seasonal=False, trace=True)\n",
    "# print(auto_model.summary())\n",
    "\n",
    "# Обучение модели ARIMA\n",
    "model = ARIMA(df['num_val'], order=(5, 1, 2))  # Пример: p=5, d=1, q=2\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Прогнозирование на 2 года (730 дней)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_steps = 365 * 2\n",
    "forecast = model_fit.get_forecast(steps=forecast_steps)\n",
    "forecast_index = pd.date_range(start=df.index[-1], periods=forecast_steps+1, inclusive='right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозированные значения и доверительные интервалы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_values = forecast.predicted_mean\n",
    "confidence_intervals = forecast.conf_int()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['num_val'], label='Исторические данные')\n",
    "plt.plot(forecast_index, forecast_values, label='Прогноз')\n",
    "plt.fill_between(forecast_index, confidence_intervals.iloc[:, 0], confidence_intervals.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.title('Прогноз загруженности станций на 2 года вперед')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Общая загруженность')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
